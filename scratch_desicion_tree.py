# -*- coding: utf-8 -*-
"""scratch desicion tree.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FK5MYIXsKh13s-aCmpNx2il79p_fsKUq
"""

class ClassifierDesicionTree:

  def __init__(self, criterion='gini', max_depth=None, min_sample_split=2, max_features = None ):
      self.criterion = criterion
      self.max_depth = max_depth
      self.min_sample_split = min_sample_split
      self.max_features = max_features

  def fit(self, predictor, target):
    self.predictor = predictor
    self.target = target

  def gini_impurity(self):
      """
      Calculate the Gini impurity of the target.

      Parameters:
      -----------
      target : array-like
        Target labels of the data.

      Returns:
      --------
      float: Gini impurity value.

      Gini impurity measures the impurity of the target labels in a single node.
      The Gini impurity value approaches 0 if all samples in a node belong to the same class,
      and approaches 0.5 if the samples are evenly divided among different classes.
      """

      # Calculate the counts of each class
      counts = np.bincount(self.target)

      # Calculate the probabilities of each class
      prob = counts / len(self.target)

      # Calculate the Gini impurity
      gini = 1 - sum(prob ** 2)

      return gini

  def entropy(self):
      """
      Calculate the Entropy of the target.

      Parameters:
      -----------
      target : array-like
        Target labels of the data.

      Returns:
      --------
      float: Entropy value.

      Entropy measures the uncertainty or randomness in the target labels in a single node.
      The entropy value approaches 0 if all samples in a node belong to the same class,
      and approaches 1 if the samples are evenly divided among different classes.
      """

      # Calculate the counts of each class
      counts = np.bincount(self.target)

      # Calculate the probabilities of each class
      prob = counts / len(self.target)

      # Calculate the Entropy
      entropy = -np.sum(prob * np.log2(prob))

      return entropy

  def log_loss(self):
      """
      Calculate the Log Loss of the target.

      Parameters:
      -----------
      target : array-like
        Target labels of the data.

      Returns:
      --------
      float: Log Loss value.

      Log Loss, also known as Cross-Entropy Loss, is a metric used to measure
      the quality of probability predictions in classification problems.
      Log Loss measures the difference between the predicted probabilities by the model
      and the true probabilities of the data. A smaller Log Loss value indicates
      better performance of the model.
      """

      # Calculate the counts of each class
      counts = np.bincount(self.target)

      # Calculate the probabilities of each class
      prob = counts / len(self.target)

      # Calculate the Log Loss
      log_loss = -1 / len(target) * (target * np.log(prob[1]) + (1 - target) * np.log(1 - prob[0])).sum()

      return log_loss

  def calculate_metric(self):
      """
      Method for obtain score metric gini, entropy, and log_loss
      """
      if self.criterion == 'gini':
        return self.gini_impurity()

      elif self.criterion == 'entropy':
        return self.entropy()

      elif self.criterion == 'log_loss':
        return self.log_loss()

      else :
        raise ValueError('Please Select gini, entropy, or logloss!')

  def splitter(self, depth=0):
      """
      Find the best split point for the decision tree based on the specified criterion.

      Returns:
      --------
      float: Best split value.

      This method iterates over unique values in the predictor variable and calculates the
      score for each split point. The score is determined based on the selected splitting
      criterion (Gini impurity, entropy, or log loss). The split point that minimizes the
      score is considered the best split value.
      """
      # Check if the current depth equals max_depth, if so, make this node a leaf node
      if self.max_depth is not None and depth >= self.max_depth:
          return None

      # Check if the number of samples in the current node is less than min_sample_split
      if len(self.predictor) < self.min_sample_split:
          return None

      # Get unique values in the predictor variable
      unique_values = np.unique(self.predictor)

      # Check if the current depth equals max_depth, if so, make this node a leaf node
      if self.max_depth is not None and depth >= self.max_depth:
          return None

      # Check if the number of samples in the current node is less than min_sample_split
      if len(self.predictor) < self.min_sample_split:
          return None

      # Get unique values in the predictor variable
      unique_values = np.unique(self.predictor)

      # Consider only a subset of features if max_features is specified
      if self.max_features is not None:
          if self.max_features == "auto" or self.max_features == "sqrt":
              n_features = len(self.predictor[0])  # Number of features
              max_features = int(np.sqrt(n_features))
          elif self.max_features == "log2":
              n_features = len(self.predictor[0])  # Number of features
              max_features = int(np.log2(n_features))
          else:
              raise ValueError("Invalid value for max_features parameter.")

          # Randomly select subset of features
          selected_features = np.random.choice(range(len(self.predictor[0])), size=max_features, replace=False)
          unique_values = np.unique(self.predictor[:, selected_features])

      # Initialize the best score with infinity and the best split value with None
      best_score = float('inf')
      best_split = None

      # Iterate over each unique value to find the best split point
      for value in unique_values:

          # Split the data based on the current value
          left_indices = np.where(self.predictor <= value)[0]
          right_indices = np.where(self.predictor > value)[0]

          # Check if the number of samples in left or right split is less than min_sample_split
          if len(left_indices) < self.min_sample_split or len(right_indices) < self.min_sample_split:
              continue

          # Get the target values for the left and right splits
          left_target = self.target[left_indices]
          right_target = self.target[right_indices]

          # Calculate the score based on the specified criterion
          if self.criterion == 'gini':

              # Calculate Gini impurity for left and right splits
              left_gini = 1 - sum(np.square(np.bincount(left_target) / len(left_target)))
              right_gini = 1 - sum(np.square(np.bincount(right_target) / len(right_target)))

              # Calculate score using Gini impurity
              score = left_gini * len(left_target) + right_gini * len(right_target)

          elif self.criterion == 'entropy':

              # Calculate entropy for left and right splits
              left_prob = np.bincount(left_target) / len(left_target)
              right_prob = np.bincount(right_target) / len(right_target)
              left_entropy = -np.sum(left_prob * np.log2(left_prob + 1e-10))  # Add a small value to avoid log(0)
              right_entropy = -np.sum(right_prob * np.log2(right_prob + 1e-10))  # Add a small value to avoid log(0)

              # Calculate score using entropy
              score = left_entropy * len(left_target) + right_entropy * len(right_target)

          elif self.criterion == 'log_loss':

              # Calculate mean probability for left and right splits
              left_prob = np.mean(left_target)
              right_prob = np.mean(right_target)

              # Add a small epsilon value to avoid log(0) or log(1)
              epsilon = 1e-10
              left_prob = np.clip(left_prob, epsilon, 1 - epsilon)
              right_prob = np.clip(right_prob, epsilon, 1 - epsilon)

              # Calculate log loss for left and right splits
              left_log_loss = -left_prob * np.log(left_prob) - (1 - left_prob) * np.log(1 - left_prob)
              right_log_loss = -right_prob * np.log(right_prob) - (1 - right_prob) * np.log(1 - right_prob)

              # Calculate score using log loss
              score = left_log_loss * len(left_target) + right_log_loss * len(right_target)

          # Update the best score and best split value if the current split has a lower score
          if score < best_score:
              best_score = score
              best_split = value

      return best_split

  def predict(self, new_data):
      """
      Predict the target labels for new data.

      Parameters
      ----------
      new_data : array-like, shape (n_samples, n_features)
          New data to be predicted.

      Returns
      -------
      predictions : array-like, shape (n_samples,)
          Predicted target labels.
      """
      prediction = []

      # find data target
      predict = np.where(new_data <= self.splitter(), 0, 1)

      # calculate sum of target 1 and 0
      for row in new_data:
          row_one = sum(element == 1 for element in row)
          row_zero = sum(element == 0 for element in row)
          if row_one > row_zero:
              prediction.append(1)
          else:
              prediction.append(0)

      return np.array(prediction)

  def metrics_classification(self, predicted_labels):
      """
      Calculate the accuracy, precision, and recall of the logistic regression model.

      Parameters:
      -----------
      predicted_labels : array-like
          Labels predicted by the model.

      Returns:
      --------
      accuracy : float
          Model accuracy.

      precision : float
          Model precision.

      recall : float
          Model recall.

      f1_score : float
          Model f1_score
      """
      # Calculate the number of correct predictions, true positives, and false positives
      correct_predictions = np.sum(predicted_labels == self.target)
      true_positives = np.sum((predicted_labels == 1) & (self.target == 1))
      false_positives = np.sum((predicted_labels == 1) & (self.target == 0))
      false_negatives = np.sum((predicted_labels == 0) & (self.target == 1))

      # Accuracy formula: (number of correct predictions) / (total predictions)
      accuracy = correct_predictions / len(self.target)

      # Precision formula: TP / (TP + FP)
      precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0

      # Recall formula: TP / (TP + FN)
      recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0

      # F1 score formula: 2 * (precision * recall) / (precision + recall)
      f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

      return accuracy, precision, recall, f1_score